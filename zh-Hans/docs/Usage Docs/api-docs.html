<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Usage Docs/api-docs">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">Spark API 文档 | LakeSoul - A Cloud Native Realtime Lakehouse Framework</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://lakesoul-io.github.io/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://lakesoul-io.github.io/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://lakesoul-io.github.io/zh-Hans/docs/Usage Docs/api-docs"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Spark API 文档 | LakeSoul - A Cloud Native Realtime Lakehouse Framework"><meta data-rh="true" name="description" content="1. 创建和写入 LakeSoulTable"><meta data-rh="true" property="og:description" content="1. 创建和写入 LakeSoulTable"><link data-rh="true" rel="icon" href="/zh-Hans/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://lakesoul-io.github.io/zh-Hans/docs/Usage Docs/api-docs"><link data-rh="true" rel="alternate" href="https://lakesoul-io.github.io/docs/Usage Docs/api-docs" hreflang="en"><link data-rh="true" rel="alternate" href="https://lakesoul-io.github.io/zh-Hans/docs/Usage Docs/api-docs" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://lakesoul-io.github.io/docs/Usage Docs/api-docs" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/zh-Hans/blog/rss.xml" title="LakeSoul - A Cloud Native Realtime Lakehouse Framework RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-Hans/blog/atom.xml" title="LakeSoul - A Cloud Native Realtime Lakehouse Framework Atom Feed"><link rel="stylesheet" href="/zh-Hans/assets/css/styles.2fb2e7d7.css">
<link rel="preload" href="/zh-Hans/assets/js/runtime~main.befebd08.js" as="script">
<link rel="preload" href="/zh-Hans/assets/js/main.02d24cf7.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh-Hans/"><div class="navbar__logo"><img src="/zh-Hans/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/zh-Hans/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">LakeSoul</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-Hans/docs/intro">文档教程</a><a class="navbar__item navbar__link" href="/zh-Hans/blog">博客</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/docs/Usage Docs/api-docs" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/zh-Hans/docs/Usage Docs/api-docs" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-Hans">简体中文</a></li></ul></div><a href="https://github.com/lakesoul-io/LakeSoul" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/zh-Hans/docs/intro">LakeSoul 介绍</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh-Hans/docs/Getting Started/setup-local-env">快速开始</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh-Hans/docs/Tutorials/consume-cdc-via-spark-streaming">使用教程</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/zh-Hans/docs/Usage Docs/setup-meta-env">使用文档</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Usage Docs/setup-meta-env">配置 LakeSoul 元数据库</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Usage Docs/setup-spark">设置 Spark/Flink 工程/作业</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/zh-Hans/docs/Usage Docs/api-docs">Spark API 文档</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Usage Docs/cdc-ingestion-table">LakeSoul CDC 表</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Usage Docs/flink-cdc-sync">LakeSoul Flink CDC 整库千表同步</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Usage Docs/flink-lakesoul-connector">LakeSoul Flink Connector</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Usage Docs/auto-compaction-task">LakeSoul 自动压缩任务教程</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/zh-Hans/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">使用文档</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Spark API 文档</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><h1>Spark API 文档</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-创建和写入-lakesoultable">1. 创建和写入 LakeSoulTable<a href="#1-创建和写入-lakesoultable" class="hash-link" aria-label="1. 创建和写入 LakeSoulTable的直接链接" title="1. 创建和写入 LakeSoulTable的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="11-table-name">1.1 Table Name<a href="#11-table-name" class="hash-link" aria-label="1.1 Table Name的直接链接" title="1.1 Table Name的直接链接">​</a></h3><p>LakeSoul 中表名可以是一个路径，数据存储的目录就是 LakeSoulTable 的表名。同时一个表可以有一个表名帮助记忆，或在SQL中访问，即不是路径形式的一个字符串。</p><p>当调用 Dataframe.write.save 方法向 LakeSoulTable 写数据时，若表不存在，则会使用存储路径自动创建新表，但是默认没有表名，只能通过路径访问，可以通过添加 <code>option(&quot;shortTableName&quot;, &quot;table_name&quot;)</code> 选项来设置表名。</p><p>通过 DataFrame.write.saveAsTable，会创建表，可以通过表名访问，路径默认为 <code>spark.sql.warehouse.dir</code>/current_database/table_name，后续可以通过路径或表名访问。如需自定义表路径，则可以加上 <code>option(&quot;path&quot;, &quot;s3://bucket/...&quot;)</code> 选项。</p><p>通过 SQL 建表时，表名可以是路径或一个表名，路径必须是绝对路径。如果是表名，则路径的规则和上面 Dataframe.write.saveAsTable 一致，可以在 <code>CREATE TABLE</code> SQL 中通过 LOCATION 子句设置。关于如何在 SQL 中创建主键分区表，可以参考 <a href="#7-%E4%BD%BF%E7%94%A8-spark-sql-%E6%93%8D%E4%BD%9C-lakesoultable">7. 使用 Spark SQL 操作 LakeSoul 表</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="12-元数据管理">1.2 元数据管理<a href="#12-元数据管理" class="hash-link" aria-label="1.2 元数据管理的直接链接" title="1.2 元数据管理的直接链接">​</a></h3><p>LakeSoul 通过数据是管理 meta 数据，因此可以高效的处理元数据，并且 meta 集群可以很方便的在云上进行扩容。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="13-partition">1.3 Partition<a href="#13-partition" class="hash-link" aria-label="1.3 Partition的直接链接" title="1.3 Partition的直接链接">​</a></h3><p>LakeSoulTable 有两种分区方式，分别是 range 分区和 hash 分区，可以两种分区同时使用。</p><ul><li>range 分区即通常的基于时间的表分区，不同分区的数据文件存储在不同的分区路径下；</li><li>使用 hash 分区，必须同时指定 hash 分区主键字段和 hash bucket num，在写数据时，会根据 bucket num 对 hash 主键字段值进行散列，取模后相同数据会写到同一个文件，文件内部根据 hash 字段值升序排列；</li><li>若同时指定了 range 分区和 hash 分区，则每个 range 分区内，hash 值相同的数据会写到同一个文件里;</li><li>指定分区后，写入 LakeSoulTable 的数据必须包含分区字段。</li></ul><p>可以根据具体场景选择使用 range 分区或 hash 分区，或者同时使用两者。当指定 hash 分区后，LakeSoulTable 的数据将根据主键唯一，主键字段为 hash 分区字段 + range 分区字段（如果存在）。</p><p>当指定 hash 分区时，LakeSoulTable 支持 upsert 操作 (scala/sql)，此时 append 模式写数据被禁止，可以使用 <code>LakeSoulTable.upsert()</code> 方法或者 <code>MERGE INTO</code> SQL 语句。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="14-代码示例">1.4 代码示例<a href="#14-代码示例" class="hash-link" aria-label="1.4 代码示例的直接链接" title="1.4 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  // 使用 SQL 功能还需要增加以下两个配置项</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.catalog.lakesoul&quot;, &quot;org.apache.spark.sql.lakesoul.catalog.LakeSoulCatalog&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.defaultCatalog&quot;, &quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import spark.implicits._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val df = Seq((&quot;2021-01-01&quot;,1,&quot;rice&quot;),(&quot;2021-01-01&quot;,2,&quot;bread&quot;)).toDF(&quot;date&quot;,&quot;id&quot;,&quot;name&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//create table</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//spark batch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df.write</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .mode(&quot;append&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;rangePartitions&quot;,&quot;date&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashPartitions&quot;,&quot;id&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashBucketNum&quot;,&quot;2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .save(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//spark streaming</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql.streaming.Trigger</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val readStream = spark.readStream.parquet(&quot;inputPath&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val writeStream = readStream.writeStream</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .outputMode(&quot;append&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .trigger(Trigger.ProcessingTime(&quot;1 minutes&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;rangePartitions&quot;,&quot;date&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashPartitions&quot;,&quot;id&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashBucketNum&quot;, &quot;2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;checkpointLocation&quot;, &quot;s3a://bucket-name/checkpoint/path&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .start(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">writeStream.awaitTermination()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//对于已存在的表，写数据时不需要再指定分区信息</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//相当于 insert overwrite partition，如果不指定 replaceWhere，则会重写整张表</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df.write</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .mode(&quot;overwrite&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;replaceWhere&quot;,&quot;date=&#x27;2021-01-01&#x27;&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .save(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-read-lakesoultable">2. Read LakeSoulTable<a href="#2-read-lakesoultable" class="hash-link" aria-label="2. Read LakeSoulTable的直接链接" title="2. Read LakeSoulTable的直接链接">​</a></h2><p>可以通过 Spark read api 或者构建 LakeSoulTable 来读取数据，LakeSoul 也支持通过 Spark SQL 读取数据，详见 <a href="#7-%E4%BD%BF%E7%94%A8-spark-sql-%E6%93%8D%E4%BD%9C-lakesoultable">7. 使用 Spark SQL 操作 LakeSoulTable</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-代码示例">2.1 代码示例<a href="#21-代码示例" class="hash-link" aria-label="2.1 代码示例的直接链接" title="2.1 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//方法一</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val df1 = spark.read.format(&quot;lakesoul&quot;).load(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//方法二</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val df2 = LakeSoulTable.forPath(tablePath).toDF</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-upsert-lakesoultable">3. Upsert LakeSoulTable<a href="#3-upsert-lakesoultable" class="hash-link" aria-label="3. Upsert LakeSoulTable的直接链接" title="3. Upsert LakeSoulTable的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-batch">3.1 Batch<a href="#31-batch" class="hash-link" aria-label="3.1 Batch的直接链接" title="3.1 Batch的直接链接">​</a></h3><p>当 LakeSoulTable 使用 hash 分区时，支持 upsert 功能。  </p><p>默认情况下使用 MergeOnRead 模式，upsert 数据以 delta file 的形式写入表路径，LakeSoul 提供了高效的 upsert 和 merge scan 性能。  </p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="311-代码示例">3.1.1 代码示例<a href="#311-代码示例" class="hash-link" aria-label="3.1.1 代码示例的直接链接" title="3.1.1 代码示例的直接链接">​</a></h4><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import spark.implicits._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forPath(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val extraDF = Seq((&quot;2021-01-01&quot;,3,&quot;chicken&quot;)).toDF(&quot;date&quot;,&quot;id&quot;,&quot;name&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.upsert(extraDF)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-streaming-支持">3.2 Streaming 支持<a href="#32-streaming-支持" class="hash-link" aria-label="3.2 Streaming 支持的直接链接" title="3.2 Streaming 支持的直接链接">​</a></h3><p>流式场景中，若 outputMode 为 complete，则每次写数据都会 overwrite 之前的数据。  </p><p>当 outputMode 为 append 或 update 时，如果指定了 hash 分区，则每次写入数据视为进行一次 upsert 更新，读取时如果存在相同主键的数据，同一字段的最新值会覆盖之前的值。仅当指定 hash 分区时，update outputMode 可用。<br>
<!-- -->若未使用 hash 分区，则允许存在重复数据。  </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-update-lakesoultable">4. Update LakeSoulTable<a href="#4-update-lakesoultable" class="hash-link" aria-label="4. Update LakeSoulTable的直接链接" title="4. Update LakeSoulTable的直接链接">​</a></h2><p>LakeSoul 支持 update 操作，通过指定条件和需要更新的字段 expression 来执行。有多种方式可以执行 update，详见 <code>LakeSoulTable</code> 注释。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-代码示例">4.1 代码示例<a href="#41-代码示例" class="hash-link" aria-label="4.1 代码示例的直接链接" title="4.1 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forPath(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql.functions._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//update(condition, set)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.update(col(&quot;date&quot;) &gt; &quot;2021-01-01&quot;, Map(&quot;data&quot; -&gt; lit(&quot;2021-01-02&quot;)))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-delete-data">5. Delete Data<a href="#5-delete-data" class="hash-link" aria-label="5. Delete Data的直接链接" title="5. Delete Data的直接链接">​</a></h2><p>LakeSoul 支持 delete 操作删除符合条件的数据，条件可以是任意字段，若不指定条件，则会删除全表数据。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="51-代码示例">5.1 代码示例<a href="#51-代码示例" class="hash-link" aria-label="5.1 代码示例的直接链接" title="5.1 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forPath(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//删除符合条件的数据</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.delete(&quot;date=&#x27;2021-01-01&#x27;&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//删除全表数据</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.delete()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-compaction">6. Compaction<a href="#6-compaction" class="hash-link" aria-label="6. Compaction的直接链接" title="6. Compaction的直接链接">​</a></h2><p>执行 upsert 会生成 delta 文件，当 delta 文件过多时，会影响读取效率，此时可以执行 compaction 合并文件。  </p><p>当执行全表 compaction 时，可以给 compaction 设置条件，只有符合条件的 range 分区才会执行 compaction 操作。  </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="61-代码示例">6.1 代码示例<a href="#61-代码示例" class="hash-link" aria-label="6.1 代码示例的直接链接" title="6.1 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forPath(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//对指定分区执行 compaction 操作</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.compaction(&quot;date=&#x27;2021-01-01&#x27;&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//对全表所有分区执行 compaction 操作</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.compaction()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//对全表所有分区执行 compaction 操作，会检测是否符合执行 compaction 的条件，只有符合条件的才会执行</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.compaction(false)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="62-compaction-后挂载到-hive-meta">6.2 Compaction 后挂载到 Hive Meta<a href="#62-compaction-后挂载到-hive-meta" class="hash-link" aria-label="6.2 Compaction 后挂载到 Hive Meta的直接链接" title="6.2 Compaction 后挂载到 Hive Meta的直接链接">​</a></h3><p>自 2.0 版本起，LakeSoul 支持将 Compaction 后的目录路径，挂载到指定的 Hive 表，并保持所有 Range 分区名不变和自定义分区名功能。该功能可以方便下游一些只能支持访问 Hive 的系统读取到 LakeSoul 的数据。更推荐的方式是通过 Kyuubi 来支持 Hive JDBC，这样可以直接使用 Hive JDBC 调用 Spark 引擎来访问 LakeSoul 表，包括 Merge on Read 读取</p><p>要使用 LakeSoul 导出分区到 Hive Meta 的功能，保持 hive 分区名不变，可以执行如下 Compaction 调用：</p><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forName(&quot;lakesoul_test_table&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.compaction(&quot;date=&#x27;2021-01-01&#x27;&quot;, &quot;spark_catalog.default.hive_test_table&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>自定义 hive 分区名，可以执行如下 Compaction 调用：</p><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forName(&quot;lakesoul_test_table&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.compaction(&quot;date=&#x27;2021-01-02&#x27;&quot;, &quot;spark_catalog.default.hive_test_table&quot;, &quot;date=&#x27;20210102&#x27;&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>注意</strong> 如果将 LakeSoul Catalog 设置为了 Spark 默认 Catalog，则 Hive 表名前面需要加上 <code>spark_catalog</code>。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-使用-spark-sql-操作-lakesoultable">7. 使用 Spark SQL 操作 LakeSoulTable<a href="#7-使用-spark-sql-操作-lakesoultable" class="hash-link" aria-label="7. 使用 Spark SQL 操作 LakeSoulTable的直接链接" title="7. 使用 Spark SQL 操作 LakeSoulTable的直接链接">​</a></h2><p>LakeSoul 支持 Spark SQL 读写数据，使用时需要设置 <code>spark.sql.catalog.lakesoul</code> 为 <code>org.apache.spark.sql.lakesoul.catalog.LakeSoulCatalog</code>。同时也可以将 LakeSoul 设置为默认 Catalog，即增加 <code>spark.sql.defaultCatalog=lakesoul</code> 配置项。
需要注意的是：</p><ul><li>不能对 hash 分区的表执行 <code>insert into</code> 功能，请使用 <code>MERGE INTO</code> SQL 语法；</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="71-代码示例">7.1 代码示例<a href="#71-代码示例" class="hash-link" aria-label="7.1 代码示例的直接链接" title="7.1 代码示例的直接链接">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="711-ddl-sql">7.1.1 DDL SQL<a href="#711-ddl-sql" class="hash-link" aria-label="7.1.1 DDL SQL的直接链接" title="7.1.1 DDL SQL的直接链接">​</a></h4><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 创建主键表，需要通过 TBLPROPERTIES 设置主键名和哈希分桶数，没有设置则为非主键表</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 创建主键CDC表，需要增加表属性 `&#x27;lakesoul_cdc_change_column&#x27;=&#x27;change_kind&#x27;`，具体请参考 [LakeSoul CDC 表](../03-Usage%20Docs/04-cdc-ingestion-table.mdx)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">default</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">table_name </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">id string</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">date</span><span class="token plain"> string</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">data</span><span class="token plain"> string</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">USING</span><span class="token plain"> lakesoul</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    PARTITIONED </span><span class="token keyword" style="color:#00009f">BY</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">date</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    LOCATION </span><span class="token string" style="color:#e3116c">&#x27;s3://bucket/table_path&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    TBLPROPERTIES</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&#x27;hashPartitions&#x27;</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;id&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&#x27;hashBucketNum&#x27;</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;2&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>同时也支持使用 ALTER TABLE 增加或删除列，该部分与 Spark SQL 语法相同，暂不支持修改列的类型。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="712-dml-sql">7.1.2 DML SQL<a href="#712-dml-sql" class="hash-link" aria-label="7.1.2 DML SQL的直接链接" title="7.1.2 DML SQL的直接链接">​</a></h4><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># INSERT INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">insert</span><span class="token plain"> overwrite</span><span class="token operator" style="color:#393A34">/</span><span class="token keyword" style="color:#00009f">into</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">table</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">default</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">table_name </span><span class="token keyword" style="color:#00009f">partition</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">date</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;2021-01-01&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">select</span><span class="token plain"> id </span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> tmpView</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># MERGE INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 对主键表，可以通过 `Merge Into` 语句来实现 Upsert</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 暂不支持 Merge Into 中 MATCHED/NOT MATCHED 带条件的语句</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ON 子句只能包含主键相等的表达式，不支持非主键列连接，不支持非相等表达式</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">MERGE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">INTO</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">default</span><span class="token punctuation" style="color:#393A34">.</span><span class="token identifier punctuation" style="color:#393A34">`</span><span class="token identifier">table_name</span><span class="token identifier punctuation" style="color:#393A34">`</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">AS</span><span class="token plain"> t </span><span class="token keyword" style="color:#00009f">USING</span><span class="token plain"> source_table </span><span class="token keyword" style="color:#00009f">AS</span><span class="token plain"> s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">ON</span><span class="token plain"> t</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">hash</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> s</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">hash</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">WHEN</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">MATCHED</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">THEN</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">UPDATE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">SET</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">WHEN</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">MATCHED</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">THEN</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">INSERT</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>注意</strong>：</p><ul><li>表名前可以添加 database(namespace) 名，默认为当前 <code>USE</code> 的 database 名，没有执行过 <code>USE database</code> 则为 <code>default</code></li><li>可以使用 LOCATION 子句或 <code>path</code> 表属性来设置表路径，如果没有设置路径，则默认为 <code>spark.sql.warehouse.dir</code>/database_name/table_name</li><li>可以使用表路径来读写一个 LakeSoul 表，在 SQL 中表名部分需要写成 lakesoul.default.<code>table_path</code></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="8-operator-on-hash-primary-keys">8. Operator on Hash Primary Keys<a href="#8-operator-on-hash-primary-keys" class="hash-link" aria-label="8. Operator on Hash Primary Keys的直接链接" title="8. Operator on Hash Primary Keys的直接链接">​</a></h2><p>指定 hash 分区后，LakeSoul 各 range 分区内的数据根据 hash 主键字段分片且分片数据有序，因此部分算子作用于 hash 主键字段时，无需 shuffle 和 sort。  </p><p>LakeSoul 目前支持 join、intersect 和 except 算子的优化，后续将支持更多算子。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="81-join-on-hash-keys">8.1 Join on Hash Keys<a href="#81-join-on-hash-keys" class="hash-link" aria-label="8.1 Join on Hash Keys的直接链接" title="8.1 Join on Hash Keys的直接链接">​</a></h3><p>支持的场景：</p><ul><li>对于同一张表，不同分区的数据根据 hash 字段进行 join 时，无需 shuffle 和 sort</li><li>若两张不同表的 hash 字段类型和字段数量相同，且 hash bucket 数量相同，它们之间根据 hash 字段进行 join 时，也无需 shuffle 和 sort</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="82-intersectexcept-on-hash-keys">8.2 Intersect/Except on Hash Keys<a href="#82-intersectexcept-on-hash-keys" class="hash-link" aria-label="8.2 Intersect/Except on Hash Keys的直接链接" title="8.2 Intersect/Except on Hash Keys的直接链接">​</a></h3><p>支持的场景：</p><ul><li>对同一张表不同分区的 hash 字段执行 intersect/except 时，无需 shuffle、sort 和 distinct</li><li>对两张不同的表，若它们拥有相同的 hash 字段类型和字段数量且 hash bucket 数量相同，对 hash 字段执行 intersect/except 时，无需 shuffle、sort 和 distinct</li></ul><p>range 分区内，hash 主键字段值是唯一的，因此 intersect 或 except 的结果是不重复的，后续操作不需要再次去重，例如可以直接 <code>count</code> 获取不重复数据的数量，无需 <code>count distinct</code>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="83-代码示例">8.3 代码示例<a href="#83-代码示例" class="hash-link" aria-label="8.3 代码示例的直接链接" title="8.3 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.catalog.lakesoul&quot;, &quot;org.apache.spark.sql.lakesoul.catalog.LakeSoulCatalog&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.defaultCatalog&quot;, &quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import spark.implicits._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val df1 = Seq((&quot;2021-01-01&quot;,1,1,&quot;rice&quot;),(&quot;2021-01-02&quot;,2,2,&quot;bread&quot;)).toDF(&quot;date&quot;,&quot;id1&quot;,&quot;id2&quot;,&quot;name&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val df2 = Seq((&quot;2021-01-01&quot;,1,1,2.7),(&quot;2021-01-02&quot;,2,2,1.3)).toDF(&quot;date&quot;,&quot;id3&quot;,&quot;id4&quot;,&quot;price&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath1 = &quot;s3a://bucket-name/table/path/is/also/table/name/1&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath2 = &quot;s3a://bucket-name/table/path/is/also/table/name/2&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df1.write</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .mode(&quot;append&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;rangePartitions&quot;,&quot;date&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashPartitions&quot;,&quot;id1,id2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashBucketNum&quot;,&quot;2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .save(tablePath1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df2.write</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .mode(&quot;append&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;rangePartitions&quot;,&quot;date&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashPartitions&quot;,&quot;id3,id4&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashBucketNum&quot;,&quot;2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .save(tablePath2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//join on hash keys without shuffle and sort</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//相同表的不同 range 分区</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.sql(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  s&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |select t1.*,t2.* from</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | (select * from lakesoul.`$tablePath1` where date=&#x27;2021-01-01&#x27;) t1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | join </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | (select * from lakesoul.`$tablePath1` where date=&#x27;2021-01-02&#x27;) t2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | on t1.id1=t2.id1 and t1.id2=t2.id2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;&quot;&quot;.stripMargin)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .show()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//相同 hash 设置的不同表</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.sql(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  s&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |select t1.*,t2.* from</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | (select * from lakesoul.`$tablePath1` where date=&#x27;2021-01-01&#x27;) t1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | join </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | (select * from lakesoul.`$tablePath2` where date=&#x27;2021-01-01&#x27;) t2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | on t1.id1=t2.id3 and t1.id2=t2.id4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;&quot;&quot;.stripMargin)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .show()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//intersect/except on hash keys without shuffle,sort and distinct</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//相同表的不同 range 分区</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.sql(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  s&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |select count(1) from </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | (select id1,id2 from lakesoul.`$tablePath1` where date=&#x27;2021-01-01&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |  intersect</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | select id1,id2 from lakesoul.`$tablePath1` where date=&#x27;2021-01-02&#x27;) t</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;&quot;&quot;.stripMargin)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .show()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//相同 hash 设置的不同表</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.sql(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  s&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |select count(1) from </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | (select id1,id2 from lakesoul.`$tablePath1` where date=&#x27;2021-01-01&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |  intersect</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | select id3,id4 from lakesoul.`$tablePath2` where date=&#x27;2021-01-01&#x27;) t</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;&quot;&quot;.stripMargin)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .show()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="9-schema-演进">9. Schema 演进<a href="#9-schema-演进" class="hash-link" aria-label="9. Schema 演进的直接链接" title="9. Schema 演进的直接链接">​</a></h2><p>LakeSoul 支持 schema 演进功能，可以新增列 (分区字段无法修改)。新增列后，读取现有数据，该新增列会是 NULL。你可以通过使用 upsert 功能，为现有数据追加该新列。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="91-merge-schema">9.1 Merge Schema<a href="#91-merge-schema" class="hash-link" aria-label="9.1 Merge Schema的直接链接" title="9.1 Merge Schema的直接链接">​</a></h3><p>在写数据时指定 <code>mergeSchema</code> 为 <code>true</code>，或者启用 <code>autoMerge</code> 来 merge schema，新的 schema 为表原本 schema 和当前写入数据 schema 的并集。  </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="92-代码示例">9.2 代码示例<a href="#92-代码示例" class="hash-link" aria-label="9.2 代码示例的直接链接" title="9.2 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">df.write</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .mode(&quot;append&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;rangePartitions&quot;,&quot;date&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashPartitions&quot;,&quot;id&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;hashBucketNum&quot;,&quot;2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  //方式一</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(&quot;mergeSchema&quot;,&quot;true&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .save(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  //方式二</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.dmetasoul.lakesoul.schema.autoMerge.enabled&quot;, &quot;true&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="10-drop-partition">10. Drop Partition<a href="#10-drop-partition" class="hash-link" aria-label="10. Drop Partition的直接链接" title="10. Drop Partition的直接链接">​</a></h2><p>删除分区，也就是删除 range 分区，实际上并不会真正删掉数据文件，可以使用 cleanup 功能清理失效数据</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="101-代码示例">10.1 代码示例<a href="#101-代码示例" class="hash-link" aria-label="10.1 代码示例的直接链接" title="10.1 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forPath(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//删除指定 range 分区</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.dropPartition(&quot;date=&#x27;2021-01-01&#x27;&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="11-drop-table">11. Drop Table<a href="#11-drop-table" class="hash-link" aria-label="11. Drop Table的直接链接" title="11. Drop Table的直接链接">​</a></h2><p>删除表会直接删除表的所有 meta 数据和文件数据</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="111-代码示例">11.1 代码示例<a href="#111-代码示例" class="hash-link" aria-label="11.1 代码示例的直接链接" title="11.1 代码示例的直接链接">​</a></h3><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lakeSoulTable = LakeSoulTable.forPath(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//删除表</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lakeSoulTable.dropTable()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/lakesoul-io/LakeSoul/tree/main/website/docs/03-Usage Docs/03-api-docs.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文档分页导航"><a class="pagination-nav__link pagination-nav__link--prev" href="/zh-Hans/docs/Usage Docs/setup-spark"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">设置 Spark/Flink 工程/作业</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zh-Hans/docs/Usage Docs/cdc-ingestion-table"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">LakeSoul CDC 表</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-创建和写入-lakesoultable" class="table-of-contents__link toc-highlight">1. 创建和写入 LakeSoulTable</a><ul><li><a href="#11-table-name" class="table-of-contents__link toc-highlight">1.1 Table Name</a></li><li><a href="#12-元数据管理" class="table-of-contents__link toc-highlight">1.2 元数据管理</a></li><li><a href="#13-partition" class="table-of-contents__link toc-highlight">1.3 Partition</a></li><li><a href="#14-代码示例" class="table-of-contents__link toc-highlight">1.4 代码示例</a></li></ul></li><li><a href="#2-read-lakesoultable" class="table-of-contents__link toc-highlight">2. Read LakeSoulTable</a><ul><li><a href="#21-代码示例" class="table-of-contents__link toc-highlight">2.1 代码示例</a></li></ul></li><li><a href="#3-upsert-lakesoultable" class="table-of-contents__link toc-highlight">3. Upsert LakeSoulTable</a><ul><li><a href="#31-batch" class="table-of-contents__link toc-highlight">3.1 Batch</a></li><li><a href="#32-streaming-支持" class="table-of-contents__link toc-highlight">3.2 Streaming 支持</a></li></ul></li><li><a href="#4-update-lakesoultable" class="table-of-contents__link toc-highlight">4. Update LakeSoulTable</a><ul><li><a href="#41-代码示例" class="table-of-contents__link toc-highlight">4.1 代码示例</a></li></ul></li><li><a href="#5-delete-data" class="table-of-contents__link toc-highlight">5. Delete Data</a><ul><li><a href="#51-代码示例" class="table-of-contents__link toc-highlight">5.1 代码示例</a></li></ul></li><li><a href="#6-compaction" class="table-of-contents__link toc-highlight">6. Compaction</a><ul><li><a href="#61-代码示例" class="table-of-contents__link toc-highlight">6.1 代码示例</a></li><li><a href="#62-compaction-后挂载到-hive-meta" class="table-of-contents__link toc-highlight">6.2 Compaction 后挂载到 Hive Meta</a></li></ul></li><li><a href="#7-使用-spark-sql-操作-lakesoultable" class="table-of-contents__link toc-highlight">7. 使用 Spark SQL 操作 LakeSoulTable</a><ul><li><a href="#71-代码示例" class="table-of-contents__link toc-highlight">7.1 代码示例</a></li></ul></li><li><a href="#8-operator-on-hash-primary-keys" class="table-of-contents__link toc-highlight">8. Operator on Hash Primary Keys</a><ul><li><a href="#81-join-on-hash-keys" class="table-of-contents__link toc-highlight">8.1 Join on Hash Keys</a></li><li><a href="#82-intersectexcept-on-hash-keys" class="table-of-contents__link toc-highlight">8.2 Intersect/Except on Hash Keys</a></li><li><a href="#83-代码示例" class="table-of-contents__link toc-highlight">8.3 代码示例</a></li></ul></li><li><a href="#9-schema-演进" class="table-of-contents__link toc-highlight">9. Schema 演进</a><ul><li><a href="#91-merge-schema" class="table-of-contents__link toc-highlight">9.1 Merge Schema</a></li><li><a href="#92-代码示例" class="table-of-contents__link toc-highlight">9.2 代码示例</a></li></ul></li><li><a href="#10-drop-partition" class="table-of-contents__link toc-highlight">10. Drop Partition</a><ul><li><a href="#101-代码示例" class="table-of-contents__link toc-highlight">10.1 代码示例</a></li></ul></li><li><a href="#11-drop-table" class="table-of-contents__link toc-highlight">11. Drop Table</a><ul><li><a href="#111-代码示例" class="table-of-contents__link toc-highlight">11.1 代码示例</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">文档</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/docs/Getting Started/setup-local-env">快速开始</a></li><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/docs/Usage Docs/setup-meta-env">使用文档</a></li><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/docs/Tutorials/consume-cdc-via-spark-streaming">使用教程</a></li></ul></div><div class="col footer__col"><div class="footer__title">社区</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/WJrHKq4BPf" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/lakesoul" target="_blank" rel="noopener noreferrer" class="footer__link-item">社交<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">更多</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/blog">博客</a></li><li class="footer__item"><a href="https://github.com/lakesoul-io/lakesoul" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 LakeSoul Project, Linux Foundation AI & Data.</div></div></div></footer></div>
<script src="/zh-Hans/assets/js/runtime~main.befebd08.js"></script>
<script src="/zh-Hans/assets/js/main.02d24cf7.js"></script>
</body>
</html>