<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Tutorials/incremental-query">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">增量查询功能教程 | LakeSoul - An Opensource Cloud Native Realtime Lakehouse Framework</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://lakesoul-io.github.io/zh-Hans/img/LakeSoul_Horizontal_White.png"><meta data-rh="true" name="twitter:image" content="https://lakesoul-io.github.io/zh-Hans/img/LakeSoul_Horizontal_White.png"><meta data-rh="true" property="og:url" content="https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/incremental-query"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="增量查询功能教程 | LakeSoul - An Opensource Cloud Native Realtime Lakehouse Framework"><meta data-rh="true" name="description" content="LakeSoul提供基于时间戳的增量查询 API，方便用户获取自给定时间戳以后新增的数据流。用户通过指定起始时间戳和结束时间戳，可以查询这一时间范围内的增量数据，如果未指定结束时间戳，则查询起始时间到当前最新时间的增量数据。"><meta data-rh="true" property="og:description" content="LakeSoul提供基于时间戳的增量查询 API，方便用户获取自给定时间戳以后新增的数据流。用户通过指定起始时间戳和结束时间戳，可以查询这一时间范围内的增量数据，如果未指定结束时间戳，则查询起始时间到当前最新时间的增量数据。"><link data-rh="true" rel="icon" href="/zh-Hans/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/incremental-query"><link data-rh="true" rel="alternate" href="https://lakesoul-io.github.io/docs/Tutorials/incremental-query" hreflang="en"><link data-rh="true" rel="alternate" href="https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/incremental-query" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://lakesoul-io.github.io/docs/Tutorials/incremental-query" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/zh-Hans/blog/rss.xml" title="LakeSoul - An Opensource Cloud Native Realtime Lakehouse Framework RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-Hans/blog/atom.xml" title="LakeSoul - An Opensource Cloud Native Realtime Lakehouse Framework Atom Feed"><link rel="stylesheet" href="/zh-Hans/assets/css/styles.74478276.css">
<link rel="preload" href="/zh-Hans/assets/js/runtime~main.05fda514.js" as="script">
<link rel="preload" href="/zh-Hans/assets/js/main.5b2e4b10.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh-Hans/"><div class="navbar__logo"><img src="/zh-Hans/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/zh-Hans/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">LakeSoul</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-Hans/docs/intro">文档教程</a><a class="navbar__item navbar__link" href="/zh-Hans/blog">博客</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/docs/Tutorials/incremental-query" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/zh-Hans/docs/Tutorials/incremental-query" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-Hans">简体中文</a></li></ul></div><a href="https://github.com/lakesoul-io/LakeSoul" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/zh-Hans/docs/intro">LakeSoul 介绍</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh-Hans/docs/Getting Started/setup-local-env">快速开始</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/zh-Hans/docs/Tutorials/consume-cdc-via-spark-streaming">使用教程</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Tutorials/consume-cdc-via-spark-streaming">通过 Spark Streaming 导入 LakeSoul CDC 表</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Tutorials/flink-cdc-sink">LakeSoul Flink CDC 整库同步使用教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Tutorials/snapshot-manage">快照相关功能用法教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Tutorials/data-mount-to-hive">将LakeSoul数据挂载到hive meta用法教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Tutorials/upsert-and-merge-udf">数据更新 (Upsert) 和 Merge UDF 使用教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Tutorials/mutil-stream-merge">多流合并构建宽表教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/Tutorials/kafka-topics-data-to-lakesoul">Kafka 多 topic 数据入 LakeSoul 教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/zh-Hans/docs/Tutorials/incremental-query">增量查询功能教程</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh-Hans/docs/Usage Docs/setup-meta-env">使用文档</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/zh-Hans/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">使用教程</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">增量查询功能教程</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><h1>增量查询功能教程</h1><p>LakeSoul提供基于时间戳的增量查询 API，方便用户获取自给定时间戳以后新增的数据流。用户通过指定起始时间戳和结束时间戳，可以查询这一时间范围内的增量数据，如果未指定结束时间戳，则查询起始时间到当前最新时间的增量数据。</p><p>LakeSoul共支持四种commit操作：mergeCommit；appendCommit；compactCommit；updateCommit，对于update操作由于历史数据每次合并会生成新文件，无法获取增量文件，因此不支持增量查询。</p><p>可选参数及含义</p><div class="language-Scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-Scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">1.分区信息</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">option(LakeSoulOptions.PARTITION_DESC, &quot;range=range1&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">option(LakeSoulOptions.HASH_PARTITIONS, &quot;hash&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">option(LakeSoulOptions.HASH_BUCKET_NUM, &quot;2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">如果未指定分区信息，则默认针对所有分区进行增量查询，如果没有range，则必须指定hash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2.起始和结束时间戳</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">option(LakeSoulOptions.READ_START_TIME, &quot;2022-01-01 15:15:15&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">option(LakeSoulOptions.READ_END_TIME, &quot;2022-01-01 20:15:15&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3.时区信息</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">option(LakeSoulOptions.TIME_ZONE,&quot;Asia/Sahanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">如果不指定时间戳的时区信息，则默认为按本机时区处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4.读类型</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">option(LakeSoulOptions.READ_TYPE, &quot;incremental&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">可以指定增量读&quot;incremental&quot;，快照读&quot;snapshot&quot;，不指定默认全量读。</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="增量读">增量读<a href="#增量读" class="hash-link" aria-label="增量读的直接链接" title="增量读的直接链接">​</a></h2><p>支持简单的upsert场景和CDC场景下的增量读，有两种方式，一种是通过调用LakeSoulTable.forPath()函数进行查询，另一种是通过spark.read指定选项进行增量读，可以获得指定分区在起止时间范围内的增量数据，获取的增量数据时间区间为前闭后开。</p><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// 针对给定range和时间戳，进行增量读,incremental表示增量读类型</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// 例如读取range1分区以上海时区为标准在2023-01-01 15:15:00到2023-01-01 15:20:00时间范围内的增量数据</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// 第一种方式，通过forPathIncremental进行增量读，不指定分区则输入&quot;&quot;，不输入时区参数则默认使用本机系统时区</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lake1 = LakeSoulTable.forPathIncremental(tablePath, &quot;range=range1&quot;, &quot;2023-01-01 15:15:00&quot;, &quot;2023-01-01 15:20:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lake2 = LakeSoulTable.forPathIncremental(tablePath, &quot;range=range1&quot;, &quot;2023-01-01 15:15:00&quot;, &quot;2023-01-01 15:20:00&quot;,&quot;Asia/Shanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// 第二种方式，通过spark.read指定选项进行增量读</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lake3 = spark.read.format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.PARTITION_DESC, &quot;range=range1&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.READ_START_TIME, &quot;2023-01-01 15:15:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.READ_END_TIME, &quot;2023-01-01 15:20:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.TIME_ZONE,&quot;Asia/Shanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.READ_TYPE, &quot;incremental&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .load(tablePath)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="流式读">流式读<a href="#流式读" class="hash-link" aria-label="流式读的直接链接" title="流式读的直接链接">​</a></h2><p>LakeSoul支持 Spark Structured Streaming read，流式读基于增量查询，通过spark.readStream指定选项进行流式读，可以获得实时数据流中指定分区下每一批次更新的增量数据。指定的起始时间需要早于实时数据的摄入时间。</p><div class="language-Scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-Scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import com.dmetasoul.lakesoul.tables.LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val spark = SparkSession.builder.master(&quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// 通过spark.readStream指定选项进行流式读，读取range1分区以上海时区为标准在2023-01-01 15:00:00及之后的增量数据，每1秒触发一次读取，将结果输出到控制台</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.readStream.format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.PARTITION_DESC, &quot;range=range1&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.READ_START_TIME, &quot;2022-01-01 15:00:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.TIME_ZONE,&quot;Asia/Shanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .option(LakeSoulOptions.READ_TYPE, &quot;incremental&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .load(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .writeStream.format(&quot;console&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .trigger(Trigger.ProcessingTime(1000))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .start()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  .awaitTermination()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="python接口教程">python接口教程<a href="#python接口教程" class="hash-link" aria-label="python接口教程的直接链接" title="python接口教程的直接链接">​</a></h2><p>将LakeSoul/python/lakesoul文件夹放入spark/python/pyspark中，通过提供pyspark.lakesoul模块，实现快照读、增量读和流式读的python API</p><div class="language-Python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-Python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 使用spark 3.3.x版本运行pyspark测试</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from pyspark.lakesoul.tables import LakeSoulTable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from pyspark.sql import SparkSession</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark = SparkSession.builder \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .appName(&quot;Stream Test&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .master(&#x27;local[4]&#x27;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .config(&quot;spark.ui.enabled&quot;, &quot;false&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .config(&quot;spark.sql.shuffle.partitions&quot;, &quot;5&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .config(&quot;spark.sql.extensions&quot;, &quot;com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .config(&quot;spark.sql.catalog.lakesoul&quot;, &quot;org.apache.spark.sql.lakesoul.catalog.LakeSoulCatalog&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .config(&quot;spark.sql.defaultCatalog&quot;, &quot;lakesoul&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .config(&quot;spark.sql.warehouse.dir&quot;, &quot;/tmp/testPyspark&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tablePath = &quot;s3a://bucket-name/table/path/is/also/table/name&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df = spark.createDataFrame([(&#x27;hash1&#x27;, 11),(&#x27;hash2&#x27;, 44),(&#x27;hash3&#x27;, 55)],[&quot;key&quot;,&quot;value&quot;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># upsert 要求必须指定hashPartition，可以不指定rangePartition</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df.write.format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .mode(&quot;append&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;hashPartitions&quot;, &quot;key&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;hashBucketNum&quot;, &quot;2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;shortTableName&quot;, &quot;tt&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .save(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lake = LakeSoulTable.forPath(spark, tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_upsert = spark.createDataFrame([(&#x27;hash5&#x27;, 100)],[&quot;key&quot;,&quot;value&quot;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 通过upsert产生增量数据，用于测试</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lake.upsert(df_upsert)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#快照读的两种方法,forPathSnapshot省略输入时区参数，则默认使用本机系统时区</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lake = spark.read.format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;readendtime&quot;, &quot;2023-02-28 14:45:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;readtype&quot;, &quot;snapshot&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .load(tablePath) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lake = LakeSoulTable.forPathSnapshot(spark,tablePath,&quot;&quot;,&quot;2023-02-28 14:45:00&quot;,&quot;Asia/Shanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#增量读的两种方法，forPathIncremental省略输入时区参数，则默认使用本机系统时区</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lake = spark.read.format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;readstarttime&quot;, &quot;2023-02-28 14:45:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;readendtime&quot;, &quot;2023-02-28 14:50:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;timezone&quot;,&quot;Asia/Shanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;readtype&quot;, &quot;incremental&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .load(tablePath) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lake = LakeSoulTable.forPathIncremental(spark,tablePath,&quot;&quot;,&quot;2023-02-28 14:45:00&quot;,&quot;2023-02-28 14:50:00&quot;,&quot;Asia/Shanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#流式读，需要开两个pyspark窗口，一个用于修改数据产生多版本数据，一个用于执行流式读</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.readStream.format(&quot;lakesoul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;readstarttime&quot;, &quot;2023-02-28 14:45:00&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;timezone&quot;,&quot;Asia/Shanghai&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .option(&quot;readtype&quot;, &quot;incremental&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .load(tablePath)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .writeStream.format(&quot;console&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .trigger(processingTime=&#x27;2 seconds&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .start()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .awaitTermination()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/lakesoul-io/LakeSoul/tree/main/website/docs/02-Tutorials/08-incremental-query.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文档分页导航"><a class="pagination-nav__link pagination-nav__link--prev" href="/zh-Hans/docs/Tutorials/kafka-topics-data-to-lakesoul"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">Kafka 多 topic 数据入 LakeSoul 教程</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zh-Hans/docs/Usage Docs/setup-meta-env"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">配置 LakeSoul 元数据库</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#增量读" class="table-of-contents__link toc-highlight">增量读</a></li><li><a href="#流式读" class="table-of-contents__link toc-highlight">流式读</a></li><li><a href="#python接口教程" class="table-of-contents__link toc-highlight">python接口教程</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">文档</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/docs/Getting Started/setup-local-env">快速开始</a></li><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/docs/Usage Docs/setup-meta-env">使用文档</a></li><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/docs/Tutorials/consume-cdc-via-spark-streaming">使用教程</a></li></ul></div><div class="col footer__col"><div class="footer__title">社区</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/WJrHKq4BPf" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/lakesoul" target="_blank" rel="noopener noreferrer" class="footer__link-item">社交<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://lists.lfaidata.foundation/g/lakesoul-announce" target="_blank" rel="noopener noreferrer" class="footer__link-item">LakeSoul Announce<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://lists.lfaidata.foundation/g/lakesoul-technical-discuss" target="_blank" rel="noopener noreferrer" class="footer__link-item">LakeSoul Technical-Discuss<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://lists.lfaidata.foundation/g/lakesoul-tsc" target="_blank" rel="noopener noreferrer" class="footer__link-item">LakeSoul TSC<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">更多</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/zh-Hans/blog">博客</a></li><li class="footer__item"><a href="https://github.com/lakesoul-io/lakesoul" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div class="customCopyright">Copyright ©2023 LakeSoul Linux基金会®, 保留所有权利. Linux基金会已经注册并使用了商标. 有关 Linux基金会的商标列表, 请参阅 <a href="https://www.linuxfoundation.org/legal/trademark-usage" target="_blank">商标使用</a> 页面. Linux 是 Linus Torvalds 的注册商标. 详情参见 <a href="https://www.linuxfoundation.org/legal/privacy-policy" target="_blank">隐私政策</a> 及 <a href="https://www.linuxfoundation.org/legal/terms" target="_blank">使用条款.</a></div></div></div></div></footer></div>
<script src="/zh-Hans/assets/js/runtime~main.05fda514.js"></script>
<script src="/zh-Hans/assets/js/main.5b2e4b10.js"></script>
</body>
</html>