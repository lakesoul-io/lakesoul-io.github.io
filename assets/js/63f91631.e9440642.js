"use strict";(self.webpackChunklakesoul_website=self.webpackChunklakesoul_website||[]).push([[5416],{1086:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>u});const o=JSON.parse('{"id":"Tutorials/data-mount-to-hive","title":"Mount LakeSoul Data to Hive Meta","description":"\x3c!--","source":"@site/docs/02-Tutorials/04-data-mount-to-hive.md","sourceDirName":"02-Tutorials","slug":"/Tutorials/data-mount-to-hive","permalink":"/docs/Tutorials/data-mount-to-hive","draft":false,"unlisted":false,"editUrl":"https://github.com/lakesoul-io/LakeSoul/tree/main/website/docs/02-Tutorials/04-data-mount-to-hive.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Snapshot Related API Usage Tutorial","permalink":"/docs/Tutorials/snapshot-manage"},"next":{"title":"Upsert Data and Merge UDF Tutorial","permalink":"/docs/Tutorials/upsert-and-merge-udf"}}');var n=a(4848),i=a(8453);const s={},l="Mount LakeSoul Data to Hive Meta",r={},u=[{value:"Keep the Same Partition Name as LakeSoul Range",id:"keep-the-same-partition-name-as-lakesoul-range",level:2},{value:"Custom Hive Partition Name",id:"custom-hive-partition-name",level:2}];function c(e){const t={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"mount-lakesoul-data-to-hive-meta",children:"Mount LakeSoul Data to Hive Meta"})}),"\n",(0,n.jsx)(t.p,{children:"Since version 2.0, LakeSoul supports two functions: attaching the directory path after Compaction to the specified Hive table, specifying the same partition name as LakeSoul, and customizing the partition name. This function can facilitate downstream systems that can only support Hive to read LakeSoul data. It is more recommended to support Hive JDBC through Kyuubi, so that you can directly use Hive JDBC to call the Spark engine to access the LakeSoul table, including Merge on Read."}),"\n",(0,n.jsx)(t.h2,{id:"keep-the-same-partition-name-as-lakesoul-range",children:"Keep the Same Partition Name as LakeSoul Range"}),"\n",(0,n.jsx)(t.p,{children:"The user can not add the hive partition name information, which is consistent with the LakeSoul partition name by default."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-scala",children:'import com.dmetasoul.lakesoul.tables.LakeSoulTable\nval lakeSoulTable = LakeSoulTable.forName("lakesoul_test_table")\nlakeSoulTable.compaction("date=\'2021-01-01\'", "spark_catalog.default.hive_test_table")\n'})}),"\n",(0,n.jsx)(t.h2,{id:"custom-hive-partition-name",children:"Custom Hive Partition Name"}),"\n",(0,n.jsx)(t.p,{children:"You can also customize the hive partition name to standardize the use of data in the hive partition."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-scala",children:'import com.dmetasoul.lakesoul.tables.LakeSoulTable\nval lakeSoulTable = LakeSoulTable.forName("lakesoul_test_table")\nlakeSoulTable.compaction("date=\'2021-01-02\'", "spark_catalog.default.hive_test_table", "date=\'20210102\'")\n'})}),"\n",(0,n.jsx)(t.p,{children:"**Note * * The function of attaching data to the hive meta needs to be used together with the compression function. Please refer to API: 6. Comparison for relevant data compression functions"})]})}function d(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},8453:(e,t,a)=>{a.d(t,{R:()=>s,x:()=>l});var o=a(6540);const n={},i=o.createContext(n);function s(e){const t=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),o.createElement(i.Provider,{value:t},e.children)}}}]);