"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[619],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>m});var n=a(7294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var o=n.createContext({}),c=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(o.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},k=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,s=e.originalType,o=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),p=c(a),k=l,m=p["".concat(o,".").concat(k)]||p[k]||u[k]||s;return a?n.createElement(m,r(r({ref:t},d),{},{components:a})):n.createElement(m,r({ref:t},d))}));function m(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var s=a.length,r=new Array(s);r[0]=k;var i={};for(var o in t)hasOwnProperty.call(t,o)&&(i[o]=t[o]);i.originalType=e,i[p]="string"==typeof e?e:l,r[1]=i;for(var c=2;c<s;c++)r[c]=a[c];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}k.displayName="MDXCreateElement"},3222:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>c});var n=a(7462),l=(a(7294),a(3905));const s={},r="LakeSoul Flink CDC Whole Database Synchronization Tutorial",i={unversionedId:"Tutorials/flink-cdc-sink/index",id:"Tutorials/flink-cdc-sink/index",title:"LakeSoul Flink CDC Whole Database Synchronization Tutorial",description:"\x3c!--",source:"@site/docs/02-Tutorials/02-flink-cdc-sink/index.md",sourceDirName:"02-Tutorials/02-flink-cdc-sink",slug:"/Tutorials/flink-cdc-sink/",permalink:"/docs/Tutorials/flink-cdc-sink/",draft:!1,editUrl:"https://github.com/lakesoul-io/LakeSoul/tree/main/website/docs/02-Tutorials/02-flink-cdc-sink/index.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"LakeSoul CDC Ingestion via Spark Streaming",permalink:"/docs/Tutorials/consume-cdc-via-spark-streaming"},next:{title:"Snapshot Related API Usage Tutorial",permalink:"/docs/Tutorials/snapshot-manage"}},o={},c=[{value:"1. Prepare the environment",id:"1-prepare-the-environment",level:2},{value:"1.1 Start a local MySQL database",id:"11-start-a-local-mysql-database",level:3},{value:"1.2 Configuring LakeSoul Meta DB and Spark Environment",id:"12-configuring-lakesoul-meta-db-and-spark-environment",level:3},{value:"1.3 Create a table in MySQL in advance and write data",id:"13-create-a-table-in-mysql-in-advance-and-write-data",level:3},{value:"2. Start the sync job",id:"2-start-the-sync-job",level:2},{value:"2.1 Start a local Flink Cluster",id:"21-start-a-local-flink-cluster",level:3},{value:"2.2 Submit LakeSoul Flink CDC Sink job",id:"22-submit-lakesoul-flink-cdc-sink-job",level:3},{value:"2.3 Use Spark SQL to read the synchronized data in the LakeSoul table",id:"23-use-spark-sql-to-read-the-synchronized-data-in-the-lakesoul-table",level:3},{value:"2.4 Observe the synchronization situation after executing Update in MySQL",id:"24-observe-the-synchronization-situation-after-executing-update-in-mysql",level:3},{value:"2.5 Observe the synchronization after executing DDL in MySQL, and read new and old data",id:"25-observe-the-synchronization-after-executing-ddl-in-mysql-and-read-new-and-old-data",level:3},{value:"2.6 Observe the synchronization after creating a new table in MySQL",id:"26-observe-the-synchronization-after-creating-a-new-table-in-mysql",level:3}],d={toc:c},p="wrapper";function u(e){let{components:t,...s}=e;return(0,l.kt)(p,(0,n.Z)({},d,s,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"lakesoul-flink-cdc-whole-database-synchronization-tutorial"},"LakeSoul Flink CDC Whole Database Synchronization Tutorial"),(0,l.kt)("p",null,"LakeSoul Flink CDC Sink supports the entire database synchronization from MySQL to LakeSoul, and can support automatic table creation, automatic schema change, exactly once semantics, etc."),(0,l.kt)("p",null,"For detailed documentation, please refer to ",(0,l.kt)("a",{parentName:"p",href:"/docs/Usage%20Docs/flink-cdc-sync"},"LakeSoul Flink CDC Synchronization of Entire MySQL Database")),(0,l.kt)("p",null,"In this tutorial, we fully demonstrate synchronizing a MySQL database to LakeSoul, including automatic table creation, DDL changes and other operations."),(0,l.kt)("h2",{id:"1-prepare-the-environment"},"1. Prepare the environment"),(0,l.kt)("h3",{id:"11-start-a-local-mysql-database"},"1.1 Start a local MySQL database"),(0,l.kt)("p",null,"It is recommended to use the MySQL Docker image to quickly start a MySQL database instance:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"docker run --name lakesoul-test-mysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=test_cdc -p 3306:3306 -d mysql:8\n")),(0,l.kt)("h3",{id:"12-configuring-lakesoul-meta-db-and-spark-environment"},"1.2 Configuring LakeSoul Meta DB and Spark Environment"),(0,l.kt)("p",null,"For this part, please refer to ",(0,l.kt)("a",{parentName:"p",href:"/docs/Getting%20Started/setup-local-env"},"Setup a local test environment")),(0,l.kt)("p",null,"Then start a ",(0,l.kt)("inlineCode",{parentName:"p"},"spark-sql")," SQL interactive query command line environment:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"$SPARK_HOME/bin/spark-sql --conf spark.sql.extensions=com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension --conf spark.sql.catalog.lakesoul=org.apache.spark.sql.lakesoul.catalog.LakeSoulCatalog --conf spark.sql.defaultCatalog=lakesoul --conf spark.sql.warehouse.dir=/tmp/lakesoul --conf spark.dmetasoul.lakesoul.snapshot.cache.expire.seconds=10\n")),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"This command starts a Spark local job, adding two options:"),(0,l.kt)("ol",{parentName:"admonition"},(0,l.kt)("li",{parentName:"ol"},"spark.sql.warehouse.dir=/tmp/lakesoul\nThis parameter is set because the default table storage location in Spark SQL needs to be set to the same directory as the Flink job output directory."),(0,l.kt)("li",{parentName:"ol"},"spark.dmetasoul.lakesoul.snapshot.cache.expire.seconds=10\nThis parameter is set because LakeSoul caches metadata information in Spark, setting a smaller cache expiration time to facilitate querying the latest data."))),(0,l.kt)("p",null,"After starting the Spark SQL command line, you can execute:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SHOW DATABASES;\nSHOW TABLES IN default;\n")),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(6847).Z,width:"1052",height:"274"})),(0,l.kt)("p",null,"You can see that there is currently only one ",(0,l.kt)("inlineCode",{parentName:"p"},"default")," database in LakeSoul, and there are no tables in it."),(0,l.kt)("h3",{id:"13-create-a-table-in-mysql-in-advance-and-write-data"},"1.3 Create a table in MySQL in advance and write data"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Install mycli",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"pip install mycli\n"))),(0,l.kt)("li",{parentName:"ol"},"Start mycli and connect to the MySQL database",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"mycli mysql://root@localhost:3306/test_cdc -p root\n"))),(0,l.kt)("li",{parentName:"ol"},"Create table and write data",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE mysql_test_1 (id INT PRIMARY KEY, name VARCHAR(255), type SMALLINT);\nINSERT INTO mysql_test_1 VALUES (1, 'Bob', 10);\nSELECT * FROM mysql_test_1;\n")))),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(4165).Z,width:"2034",height:"574"})),(0,l.kt)("h2",{id:"2-start-the-sync-job"},"2. Start the sync job"),(0,l.kt)("h3",{id:"21-start-a-local-flink-cluster"},"2.1 Start a local Flink Cluster"),(0,l.kt)("p",null,"You can download from the Flink download page: ",(0,l.kt)("a",{parentName:"p",href:"https://www.apache.org/dyn/closer.lua/flink/flink-1.17.1/flink-1.17.1-bin-scala_2.12.tgz"},"Flink 1.17")),(0,l.kt)("p",null,"Unzip the downloaded Flink installation package:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"tar xf flink-1.17.1-bin-scala_2.12.tgz\nexport FLINK_HOME=${PWD}/flink-1.17.1\n")),(0,l.kt)("p",null,"Then start a local Flink Cluster:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"$FLINK_HOME/bin/start-cluster.sh\n")),(0,l.kt)("p",null,"You can open http://localhost:8081 to see if the Flink local cluster has started normally:\n",(0,l.kt)("img",{src:a(5033).Z,width:"3116",height:"934"})),(0,l.kt)("h3",{id:"22-submit-lakesoul-flink-cdc-sink-job"},"2.2 Submit LakeSoul Flink CDC Sink job"),(0,l.kt)("p",null,"Submit a LakeSoul Flink CDC Sink job to the Flink cluster started above:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"./bin/flink run -ys 1 -yjm 1G -ytm 2G \\\n   -c org.apache.flink.lakesoul.entry.MysqlCdc\\\n   lakesoul-flink-2.3.0-flink-1.17.jar \\\n   --source_db.host localhost \\\n   --source_db.port 3306 \\\n   --source_db.db_name test_cdc \\\n   --source_db.user root \\\n   --source_db.password root \\\n   --source.parallelism 1 \\\n   --sink.parallelism 1 \\\n   --warehouse_path file:/tmp/lakesoul \\\n   --flink.checkpoint file:/tmp/flink/chk \\\n   --flink.savepoint file:/tmp/flink/svp \\\n   --job.checkpoint_interval 10000 \\\n   --server_time_zone UTC\n")),(0,l.kt)("p",null,"The jar package of lakesoul-flink can be downloaded from the ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/lakesoul-io/LakeSoul/releases/"},"Github Release")," page."),(0,l.kt)("p",null,"Refer to ",(0,l.kt)("a",{parentName:"p",href:"/docs/Usage%20Docs/flink-cdc-sync"},"LakeSoul Flink CDC Synchronization of Entire MySQL Database")," for detailed usage of the Flink job."),(0,l.kt)("p",null,"On the http://localhost:8081 Flink job page, click Running Job to check whether the LakeSoul job is already in the ",(0,l.kt)("inlineCode",{parentName:"p"},"Running")," state."),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(9509).Z,width:"3738",height:"828"})),(0,l.kt)("p",null,"You can click to enter the job page, and you should see that one data record has been synchronized:\n",(0,l.kt)("img",{src:a(8387).Z,width:"3666",height:"1648"})),(0,l.kt)("h3",{id:"23-use-spark-sql-to-read-the-synchronized-data-in-the-lakesoul-table"},"2.3 Use Spark SQL to read the synchronized data in the LakeSoul table"),(0,l.kt)("p",null,"Execute in Spark SQL Shell:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SHOW DATABASES;\nSHOW TABLES IN test_cdc;\nDESC test_cdc.mysql_test_1;\nSELECT * FROM test_cdc.mysql_test_1;\n")),(0,l.kt)("p",null,"You can see the running result of each statement, that is, a ",(0,l.kt)("inlineCode",{parentName:"p"},"test_cdc")," database is automatically created in ",(0,l.kt)("strong",{parentName:"p"},"LakeSoul, and a ",(0,l.kt)("inlineCode",{parentName:"strong"},"mysql_test_1")," table is automatically created. The fields and primary keys of the table are the same as those of MySQL")," (one more rowKinds column, refer to the description in ",(0,l.kt)("a",{parentName:"p",href:"/docs/Usage%20Docs/cdc-ingestion-table"},"LakeSoul CDC Table"),")."),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(9625).Z,width:"1038",height:"838"})),(0,l.kt)("h3",{id:"24-observe-the-synchronization-situation-after-executing-update-in-mysql"},"2.4 Observe the synchronization situation after executing Update in MySQL"),(0,l.kt)("p",null,"Perform the update in mycli:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"UPDATE mysql_test_1 SET name='Peter' WHERE id=1;\n")),(0,l.kt)("p",null,"Then read again in LakeSoul:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM test_cdc.mysql_test_1;\n")),(0,l.kt)("p",null,"You can see that the latest data has been read:\n",(0,l.kt)("img",{src:a(8333).Z,width:"876",height:"148"})),(0,l.kt)("h3",{id:"25-observe-the-synchronization-after-executing-ddl-in-mysql-and-read-new-and-old-data"},"2.5 Observe the synchronization after executing DDL in MySQL, and read new and old data"),(0,l.kt)("p",null,"Modify the structure of the table in mycli:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER TABLE mysql_test_1 ADD COLUMN new_col FLOAT;\n")),(0,l.kt)("p",null,"That is to add a new column at the end, the default is null. Verify the execution result in mycli:\n",(0,l.kt)("img",{src:a(9862).Z,width:"1486",height:"992"})),(0,l.kt)("p",null,"At this point, the table structure has been synchronized in LakeSoul, and we can view the table structure in spark-sql:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"DESC test_cdc.mysql_test_1;\n")),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(8395).Z,width:"808",height:"418"})),(0,l.kt)("p",null,"At this time, read data from LakeSoul, and the new column is also null:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM test_cdc.mysql_test_1;\n")),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(8367).Z,width:"922",height:"150"})),(0,l.kt)("p",null,"Insert a new piece of data into MySQL:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO mysql_test_1 VALUES (2, 'Alice', 20, 9.9);\n")),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(9543).Z,width:"1584",height:"508"})),(0,l.kt)("p",null,"Read again from LakeSoul:\n",(0,l.kt)("img",{src:a(7864).Z,width:"1036",height:"188"})),(0,l.kt)("p",null,"Delete a piece of data from MySQL:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"delete from mysql_test_1 where id=1;\n")),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(8305).Z,width:"1228",height:"582"})),(0,l.kt)("p",null,"Read from LakeSoul:\n",(0,l.kt)("img",{src:a(3737).Z,width:"998",height:"152"})),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"You can see that LakeSoul reads the synchronized result every time, which is exactly the same as in MySQL. ")),(0,l.kt)("h3",{id:"26-observe-the-synchronization-after-creating-a-new-table-in-mysql"},"2.6 Observe the synchronization after creating a new table in MySQL"),(0,l.kt)("p",null,"Create a new table in MySQL with a different schema from the previous table:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE mysql_test_2 (name VARCHAR(100) PRIMARY KEY, phone_no VARCHAR(20));\n")),(0,l.kt)("p",null,(0,l.kt)("img",{src:a(3973).Z,width:"2026",height:"510"})),(0,l.kt)("p",null,"In LakeSoul, you can see that the new table has been automatically created, and you can view the table structure:\n",(0,l.kt)("img",{src:a(1785).Z,width:"902",height:"490"})),(0,l.kt)("p",null,"Insert a piece of data into a new MySQL table:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO mysql_test_2 VALUES ('Bob', '10010');\n")),(0,l.kt)("p",null,"LakeSoul also successfully synchronized and read the data of the new table:\n",(0,l.kt)("img",{src:a(9768).Z,width:"910",height:"114"})))}u.isMDXComponent=!0},9509:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/flink-cdc-job-submitted-5afb5e18b04cf3cf79eeb7a0e4aad05b.png"},8387:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/flink-cdc-sync-1-c6a93513ff48347fa8297cfda14f6402.png"},5033:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/flnk-cluster-empty-9dccdcd8ed47252d8d52395ec04aa607.png"},3973:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/mysql-create-table-2-f09877f7865f317881d56e09f70633e6.png"},4165:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/mysql-init-insert-1-2765502bf425a2d1dabb028ea15155ea.png"},9543:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/mysql-insert-new-1-4956bac0d7d6709e1852ffecfae7c509.png"},8305:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/mysql-read-after-delete-30495413d60d01dcbda0f1afda920f5e.png"},9862:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/mysql-update-1-707701b0ae38f5a014cff7935d9d0885.png"},9625:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-read-1-6b5e746a1d6ae5527554c1b0d128883b.png"},8333:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-read-2-86637e8e5623e101c469232eef438c37.png"},8395:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-read-after-add-col-1-e59d8aeada4ad213e81b8c9fe6b28005.png"},8367:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-read-after-add-col-2-5258ab0f98aa664ebcb83ce29f91dd8e.png"},7864:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-read-after-add-col-3-120181b9bbd4280b132fc8c825eb07c6.png"},3737:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-read-after-delete-0ce048ee0d34f1af6f45562c0045e08f.png"},9768:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-read-after-new-table-b6a5db4dabdd816c0f88007ba5d589a8.png"},1785:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-show-after-new-table-13d0f25f28dca4e42dfc6e395aaf8a2d.png"},6847:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark-sql-show-db-empty-440f1c01b78ce74f800bc740ece60c92.png"}}]);