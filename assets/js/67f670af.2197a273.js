"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[334],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>k});var n=a(7294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var s=n.createContext({}),u=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=u(e.components);return n.createElement(s.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,r=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),p=u(a),c=l,k=p["".concat(s,".").concat(c)]||p[c]||m[c]||r;return a?n.createElement(k,i(i({ref:t},d),{},{components:a})):n.createElement(k,i({ref:t},d))}));function k(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=a.length,i=new Array(r);i[0]=c;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[p]="string"==typeof e?e:l,i[1]=o;for(var u=2;u<r;u++)i[u]=a[u];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},5162:(e,t,a)=>{a.d(t,{Z:()=>i});var n=a(7294),l=a(6010);const r={tabItem:"tabItem_Ymn6"};function i(e){let{children:t,hidden:a,className:i}=e;return n.createElement("div",{role:"tabpanel",className:(0,l.Z)(r.tabItem,i),hidden:a},t)}},4866:(e,t,a)=>{a.d(t,{Z:()=>S});var n=a(7462),l=a(7294),r=a(6010),i=a(2466),o=a(6550),s=a(1980),u=a(7392),d=a(12);function p(e){return function(e){return l.Children.map(e,(e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:l}}=e;return{value:t,label:a,attributes:n,default:l}}))}function m(e){const{values:t,children:a}=e;return(0,l.useMemo)((()=>{const e=t??p(a);return function(e){const t=(0,u.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function c(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function k(e){let{queryString:t=!1,groupId:a}=e;const n=(0,o.k6)(),r=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,s._X)(r),(0,l.useCallback)((e=>{if(!r)return;const t=new URLSearchParams(n.location.search);t.set(r,e),n.replace({...n.location,search:t.toString()})}),[r,n])]}function h(e){const{defaultValue:t,queryString:a=!1,groupId:n}=e,r=m(e),[i,o]=(0,l.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!c({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:r}))),[s,u]=k({queryString:a,groupId:n}),[p,h]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[n,r]=(0,d.Nk)(a);return[n,(0,l.useCallback)((e=>{a&&r.set(e)}),[a,r])]}({groupId:n}),g=(()=>{const e=s??p;return c({value:e,tabValues:r})?e:null})();(0,l.useLayoutEffect)((()=>{g&&o(g)}),[g]);return{selectedValue:i,selectValue:(0,l.useCallback)((e=>{if(!c({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);o(e),u(e),h(e)}),[u,h,r]),tabValues:r}}var g=a(2389);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function f(e){let{className:t,block:a,selectedValue:o,selectValue:s,tabValues:u}=e;const d=[],{blockElementScrollPositionUntilNextRender:p}=(0,i.o5)(),m=e=>{const t=e.currentTarget,a=d.indexOf(t),n=u[a].value;n!==o&&(p(t),s(n))},c=e=>{let t=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const a=d.indexOf(e.currentTarget)+1;t=d[a]??d[0];break}case"ArrowLeft":{const a=d.indexOf(e.currentTarget)-1;t=d[a]??d[d.length-1];break}}t?.focus()};return l.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":a},t)},u.map((e=>{let{value:t,label:a,attributes:i}=e;return l.createElement("li",(0,n.Z)({role:"tab",tabIndex:o===t?0:-1,"aria-selected":o===t,key:t,ref:e=>d.push(e),onKeyDown:c,onClick:m},i,{className:(0,r.Z)("tabs__item",b.tabItem,i?.className,{"tabs__item--active":o===t})}),a??t)})))}function v(e){let{lazy:t,children:a,selectedValue:n}=e;const r=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===n));return e?(0,l.cloneElement)(e,{className:"margin-top--md"}):null}return l.createElement("div",{className:"margin-top--md"},r.map(((e,t)=>(0,l.cloneElement)(e,{key:t,hidden:e.props.value!==n}))))}function N(e){const t=h(e);return l.createElement("div",{className:(0,r.Z)("tabs-container",b.tabList)},l.createElement(f,(0,n.Z)({},e,t)),l.createElement(v,(0,n.Z)({},e,t)))}function S(e){const t=(0,g.Z)();return l.createElement(N,(0,n.Z)({key:String(t)},e))}},8264:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>s,default:()=>k,frontMatter:()=>o,metadata:()=>u,toc:()=>p});var n=a(7462),l=(a(7294),a(3905)),r=a(4866),i=a(5162);const o={},s="Flink Getting Started Guide",u={unversionedId:"Getting Started/Flink-Guide",id:"Getting Started/Flink-Guide",title:"Flink Getting Started Guide",description:"\x3c!--",source:"@site/docs/01-Getting Started/03-Flink-Guide.mdx",sourceDirName:"01-Getting Started",slug:"/Getting Started/Flink-Guide",permalink:"/docs/Getting Started/Flink-Guide",draft:!1,editUrl:"https://github.com/lakesoul-io/LakeSoul/tree/main/website/docs/01-Getting Started/03-Flink-Guide.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Spark Getting Started Guide",permalink:"/docs/Getting Started/spark-guide"},next:{title:"LakeSoul CDC Ingestion via Spark Streaming",permalink:"/docs/Tutorials/consume-cdc-via-spark-streaming"}},d={},p=[{value:"Support Matrix",id:"support-matrix",level:2},{value:"PG Configuration",id:"pg-configuration",level:2},{value:"SQL",id:"sql",level:2},{value:"Download LakeSoul Flink Jar",id:"download-lakesoul-flink-jar",level:3},{value:"Start SQL Client",id:"start-sql-client",level:3},{value:"Create Table",id:"create-table",level:2},{value:"Drop Table",id:"drop-table",level:2},{value:"Insert Data",id:"insert-data",level:2},{value:"Update Data",id:"update-data",level:2},{value:"Delete Data",id:"delete-data",level:2},{value:"Query Data",id:"query-data",level:2},{value:"Full Read",id:"full-read",level:3},{value:"Snapshot Batch Read",id:"snapshot-batch-read",level:3},{value:"Incremental Range Read",id:"incremental-range-read",level:3},{value:"Streaming Read",id:"streaming-read",level:3},{value:"Lookup Join",id:"lookup-join",level:3}],m={toc:p},c="wrapper";function k(e){let{components:t,...a}=e;return(0,l.kt)(c,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"flink-getting-started-guide"},"Flink Getting Started Guide"),(0,l.kt)("h2",{id:"support-matrix"},"Support Matrix"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"LakeSoul"),(0,l.kt)("th",{parentName:"tr",align:null},"Flink"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"2.4.x+"),(0,l.kt)("td",{parentName:"tr",align:null},"1.17")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"2.1.x-2.3.x"),(0,l.kt)("td",{parentName:"tr",align:null},"1.14")))),(0,l.kt)("h2",{id:"pg-configuration"},"PG Configuration"),(0,l.kt)("p",null,"Add the following configuration to ",(0,l.kt)("inlineCode",{parentName:"p"},"$FLINK_HOME/conf/flink-conf.yaml"),":"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"containerized.master.env.LAKESOUL_PG_DRIVER: com.lakesoul.shaded.org.postgresql.Driver\ncontainerized.master.env.LAKESOUL_PG_USERNAME: root\ncontainerized.master.env.LAKESOUL_PG_PASSWORD: root\ncontainerized.master.env.LAKESOUL_PG_URL: jdbc:postgresql://localhost:5432/test_lakesoul_meta?stringtype=unspecified\ncontainerized.taskmanager.env.LAKESOUL_PG_DRIVER: com.lakesoul.shaded.org.postgresql.Driver\ncontainerized.taskmanager.env.LAKESOUL_PG_USERNAME: root\ncontainerized.taskmanager.env.LAKESOUL_PG_PASSWORD: root\ncontainerized.taskmanager.env.LAKESOUL_PG_URL: jdbc:postgresql://localhost:5432/test_lakesoul_meta?stringtype=unspecified\n")),(0,l.kt)("p",null,"Note that both the master and taskmanager environment variables need to be set."),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"The connection information, username and password of the Postgres database need to be modified according to the actual deployment.")),(0,l.kt)("admonition",{type:"caution"},(0,l.kt)("p",{parentName:"admonition"},"Note that if you use Session mode to start a job, that is, submit the job to Flink Standalone Cluster as a client, ",(0,l.kt)("inlineCode",{parentName:"p"},"flink run")," as a client will not read the above configuration, so you need to configure the environment variables separately, namely:"),(0,l.kt)("pre",{parentName:"admonition"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"export LAKESOUL_PG_DRIVER=com.lakesoul.shaded.org.postgresql.Driver\nexport LAKESOUL_PG_URL=jdbc:postgresql://localhost:5432/test_lakesoul_meta?stringtype=unspecified\nexport LAKESOUL_PG_USERNAME=root\nexport LAKESOUL_PG_PASSWORD=root\n"))),(0,l.kt)("h2",{id:"sql"},"SQL"),(0,l.kt)("h3",{id:"download-lakesoul-flink-jar"},"Download LakeSoul Flink Jar"),(0,l.kt)("p",null,"It can be downloaded from the LakeSoul Release page: ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/lakesoul-io/LakeSoul/releases/download/v2.5.0/lakesoul-flink-2.5.0-flink-1.17.jar"},"https://github.com/lakesoul-io/LakeSoul/releases/download/v2.5.0/lakesoul-flink-2.5.0-flink-1.17.jar"),"."),(0,l.kt)("h3",{id:"start-sql-client"},"Start SQL Client"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"# Start Flink SQL Client\nbin/sql-client.sh embedded -j lakesoul-flink-2.5.0-flink-1.17.jar\n")),(0,l.kt)("h2",{id:"create-table"},"Create Table"),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},'TableEnvironment tEnv = TableEnvironment.create(EnvironmentSettings.inBatchMode());\nString createUserSql = "create table user_info (" +\n        "`id` INT," +\n        "name STRING," +\n        "score INT," +\n        "`date` STRING," +\n        "region STRING," +\n         " PRIMARY KEY (`id`,`name`) NOT ENFORCED"+\n        ") PARTITIONED BY (`region`,`date`)"+\n         " WITH (" +\n        " \'connector\'=\'lakesoul\'," +\n        " \'hashBucketNum\'=\'4\'," +\n        " \'use_cdc\'=\'true\'," +\n        " \'path\'=\'/tmp/lakesoul/flink/sink/test\' )";\ntEnv. executeSql(createUserSql);\n'))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"-- Create the test_table table, use id and name as the joint primary key, use region and date as the two-level range partition, catalog is lakesoul, and database is default\ncreate table `lakesoul`.`default`.test_table (\n            `id` INT,\n            name STRING,\n            score INT,\n            `date` STRING,\n            region STRING,\n        PRIMARY KEY (`id`,`name`) NOT ENFORCED\n        ) PARTITIONED BY (`region`,`date`)\n        WITH (\n            'connector'='lakesoul',\n            'hashBucketNum'='4',\n            'use_cdc'='true',\n            'path'='file:///tmp/lakesoul/flink/sink/test');\n")))),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"The meaning of the parameters for creating a table"),(0,l.kt)("table",{parentName:"admonition"},(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,l.kt)("th",{parentName:"tr",align:null},"Explanation"),(0,l.kt)("th",{parentName:"tr",align:null},"Value Format"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"PARTITIONED BY"),(0,l.kt)("td",{parentName:"tr",align:null},"used to specify the range partition field of the table, if there is no range partition field, it will be omitted"),(0,l.kt)("td",{parentName:"tr",align:null},"PARTITIONED BY (",(0,l.kt)("inlineCode",{parentName:"td"},"date"),")")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"PRIMARY KEY"),(0,l.kt)("td",{parentName:"tr",align:null},"used to specify one or more primary keys"),(0,l.kt)("td",{parentName:"tr",align:null},"PARIMARY KEY (",(0,l.kt)("inlineCode",{parentName:"td"},"id"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"name"),") NOT ENFORCED")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"connector"),(0,l.kt)("td",{parentName:"tr",align:null},"data source connector, used to specify the data source type"),(0,l.kt)("td",{parentName:"tr",align:null},"'connector'='lakesoul'")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"hashBucketNum"),(0,l.kt)("td",{parentName:"tr",align:null},"table with primary key(s) must have this property set to a number >= 0"),(0,l.kt)("td",{parentName:"tr",align:null},"'hashBucketNum'='4'")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"path"),(0,l.kt)("td",{parentName:"tr",align:null},"used to specify the storage path of the table"),(0,l.kt)("td",{parentName:"tr",align:null},"'path'='file:///tmp/lakesoul/flink/sink/test'")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"use_cdc"),(0,l.kt)("td",{parentName:"tr",align:null},"Set whether the table is in CDC format (refer to ",(0,l.kt)("a",{parentName:"td",href:"/docs/Usage%20Docs/cdc-ingestion-table"},"CDC Table Format")," )"),(0,l.kt)("td",{parentName:"tr",align:null},"'use_cdc'='true'"))))),(0,l.kt)("h2",{id:"drop-table"},"Drop Table"),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},'tEnvs.executeSql("DROP TABLE if exists test_table");\n'))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE if exists test_table;\n")))),(0,l.kt)("h2",{id:"insert-data"},"Insert Data"),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},"tEnvs.executeSql(\"insert into `lakesoul`.`default`.test_table values (1, 'AAA', 98, '2023-05-10', 'China')\"). await();\n"))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("p",null,"  Batch insert:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"insert into `lakesoul`.`default`.test_table values (1,'AAA', 98, '2023-05-10', 'China');\n")),(0,l.kt)("p",null,"  Streaming: read data from another stream source and write into LakeSoul. If upstream source is a Changelog stream, then LakeSoul table should be created with CDC format enabled."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"insert into `lakesoul`.`default`.test_table select * from `lakesoul`.`cdcsink`.soure_table;\n")))),(0,l.kt)("admonition",{type:"caution"},(0,l.kt)("ol",{parentName:"admonition"},(0,l.kt)("li",{parentName:"ol"},"For stream writing, checkpoint interval needs to be set, and it is recommended to be more than 1 minute;"),(0,l.kt)("li",{parentName:"ol"},"Set the corresponding time zone according to the environment:")),(0,l.kt)("pre",{parentName:"admonition"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SET 'table.local-time-zone' = 'Asia/Shanghai';\n-- Set the checkpointing interval\nSET 'execution.checkpointing.interval' = '2min';\n"))),(0,l.kt)("h2",{id:"update-data"},"Update Data"),(0,l.kt)("p",null,"For batch mode only."),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},'tEnvs.executeSql("UPDATE `lakesoul`.`default`.test_table set score = 100 where id = 1") await();\n'))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"UPDATE `lakesoul`.`default`.test_table set score = 100 where id = 1;\n")))),(0,l.kt)("admonition",{type:"caution"},(0,l.kt)("p",{parentName:"admonition"},"Note that in the case of ",(0,l.kt)("inlineCode",{parentName:"p"},"update"),", updating the values of primary key and partition columns is not allowed. For the stream execution mode, LakeSoul has been able to support ChangeLog semantics, which can support additions, deletions and modifications.")),(0,l.kt)("h2",{id:"delete-data"},"Delete Data"),(0,l.kt)("p",null,"For batch mode only."),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},'tEnvs.executeSql("DELETE FROM `lakesoul`.`default`.test_table where id = 1") await();\n'))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"DELETE FROM `lakesoul`.`default`.test_table where id = 1;\n")))),(0,l.kt)("admonition",{type:"caution"},(0,l.kt)("p",{parentName:"admonition"},"In the case of ",(0,l.kt)("inlineCode",{parentName:"p"},"delete"),", partitioning columns in the condition are not allowed.For the stream execution mode, LakeSoul has been able to support ChangeLog semantics, which can support additions, deletions and modifications.")),(0,l.kt)("h2",{id:"query-data"},"Query Data"),(0,l.kt)("h3",{id:"full-read"},"Full Read"),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},"// Create a batch execution environment\ntEnvs.executeSql(\"SELECT * FROM `lakesoul`.`default`.test_table where region='China' and `date`='2023-05-10'\").print();\n"))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM `lakesoul`.`default`.test_table where region='China' and `date`='2023-05-10';\n")))),(0,l.kt)("h3",{id:"snapshot-batch-read"},"Snapshot Batch Read"),(0,l.kt)("p",null,"LakeSoul supports snapshot reading of tables, and users can query all data before the end timestamp by specifying partition information and end timestamp."),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},"tEnvs.executeSql(\"SELECT * FROM `lakesoul`.`default`.test_table /*+ OPTIONS('readtype'='snapshot', 'readendtime'='2023-05-01 15:20:15', 'timezone'='Asia/Shanghai')*/ WHERE region='China'\").print();\n"))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"-- Execute snapshot read of test_table in the region=China partition, the end timestamp of the read is 2023-05-01 15:20:15, and the time zone is Asia/Shanghai\nSELECT * FROM `lakesoul`.`default`.test_table /*+ OPTIONS('readtype'='snapshot', 'readendtime'='2023-05-01 15:20:15', 'timezone'='Asia/Shanghai')*/ WHERE region='China';\n")))),(0,l.kt)("h3",{id:"incremental-range-read"},"Incremental Range Read"),(0,l.kt)("p",null,"LakeSoul supports range incremental reads for tables. Users can query incremental data within this time range by specifying partition information, start timestamp, and end timestamp."),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"}," tEnvs.executeSql(\"SELECT * FROM `lakesoul`.`default`.test_table /*+ OPTIONS('readtype'='incremental'\uff0c'readstarttime'='2023-05-01 15:15:15 ', 'readendtime'='2023-05-01 15:20:15', 'timezone'='Asia/Shanghai')*/ WHERE region='China'\").print();\n"))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"-- Incremental reading of test_table in the region=China partition, the read timestamp range is 2023-05-01 15:15:15 to 2023-05-01 15:20:15, and the time zone is Asia/Shanghai\nSELECT * FROM `lakesoul`.`default`.test_table /*+ OPTIONS('readtype'='incremental', 'readstarttime'='2023-05-01 15:15:15 ', 'readendtime'='2023-05-01 15:20:15', 'timezone'='Asia/Shanghai')*/ WHERE region='China';\n")))),(0,l.kt)("h3",{id:"streaming-read"},"Streaming Read"),(0,l.kt)("p",null,"The LakeSoul table supports streaming reads in Flink. Streaming reads are based on incremental reads. By specifying the start timestamp and partition information, users can continuously and uninterruptedly read new data after the start timestamp.\nIf start timestamp is not specified, it will read from the first data\u3002"),(0,l.kt)(r.Z,{defaultValue:"SQL",values:[{label:"Java",value:"Java"},{label:"SQL",value:"SQL"}],mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"Java",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-java"},"tEnvs.executeSql(\"SELECT * FROM `lakesoul`.`default`.test_table /*+ OPTIONS('timezone'='Asia/Shanghai')*/ WHERE region='China'\").print();\n"))),(0,l.kt)(i.Z,{value:"SQL",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"-- Incremental reading of test_table in the region=China partition, the time zone is Asia/Shanghai\nSELECT * FROM `lakesoul`.`default`.test_table /*+ OPTIONS('timezone'='Asia/Shanghai')*/ WHERE region='China';\n")))),(0,l.kt)("p",null,"LakeSoul fully supports Flink Changelog Stream semantics when streaming. For the LakeSoul CDC table, the result of incremental reading is still in CDC format, that is, it contains ",(0,l.kt)("inlineCode",{parentName:"p"},"insert"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"update"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"delete")," events, and these events will be automatically converted to the corresponding values of the RowKind field of Flink's RowData class object, so that in Flink incremental pipeline calculation is achieved."),(0,l.kt)("h3",{id:"lookup-join"},"Lookup Join"),(0,l.kt)("p",null,"LakeSoul supports Lookup Join operations of Flink SQL. Lookup Join will cache the right table to be joined in memory, thereby greatly improving the join speed, and can be used in scenarios where relatively small dimension tables are joined. LakeSoul tries to refresh the cache every 60 seconds by default, you could change this by setting ",(0,l.kt)("inlineCode",{parentName:"p"},"'lookup.join.cache.ttl'='60s'")," property when creating the dimension table."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE `lakesoul`.`default`.customers (\n            `c_id` INT,\n            `name` STRING,\n        PRIMARY KEY (`c_id`) NOT ENFORCED)\n        WITH (\n            'connector'='lakesoul',\n            'hashBucketNum'='1',\n            'path'='file:///tmp/lakesoul/flink/sink/customers'\n            );  \nCREATE TABLE `lakesoul`.`default`.orders (\n            `o_id` INT,\n            `o_c_id` INT,\n        PRIMARY KEY (`o_id`) NOT ENFORCED)\n        WITH (\n            'connector'='lakesoul',\n            'hashBucketNum'='1',\n            'path'='file:///tmp/lakesoul/flink/sink/orders',\n            'lookup.join.cache.ttl'='60s'\n            );  \nSELECT `o_id`, `c_id`, `name`\nFROM\n(SELECT *, proctime() as proctime FROM `lakesoul`.`default`.orders) as o\nJOIN `lakesoul`.`default`.customers FOR SYSTEM_TIME AS OF o.proctime\nON c_id = o_cid;\n")),(0,l.kt)("p",null,"The Orders table is enriched with data from the Customers table. The FOR SYSTEM_TIME AS OF clause with the subsequent processing time attribute ensures that each row of the Orders table is joined with those Customers rows that match the join predicate at the point in time when the Orders row is processed by the join operator. It also prevents that the join result is updated when a joined Customer row is updated in the future. The lookup join also requires a mandatory equality join predicate, in the example above o.oc_id = c.id."),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"LakeSoul supports read LakeSoul tables in batch and stream mode, execute commands on the Flink SQLClient client, and switch between stream and batch execution modes."),(0,l.kt)("pre",{parentName:"admonition"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"-- Execute Flink tasks according to the stream\nSET execution.runtime-mode = streaming;\nSET 'execution.checkpointing.interval' = '1min';\n-- Execute Flink tasks in batch mode\nSET execution.runtime-mode = batch;\n")),(0,l.kt)("p",{parentName:"admonition"},"Using Flink SQL, the format of the specified conditional query is ",(0,l.kt)("inlineCode",{parentName:"p"},"SELECT * FROM test_table /*+ OPTIONS('key'='value')*/ WHERE partition=somevalue"),". In all of the following read modes, you could optionally specify partition values in ",(0,l.kt)("inlineCode",{parentName:"p"},"WHERE")," clause to either specify the exact all partition values or just a subset of partitions values. LakeSoul will find the partitions that match the partition filters.\nIn the query, ",(0,l.kt)("inlineCode",{parentName:"p"},"/* OPTIONS() */")," are query options (hints). Hints must be placed directly after the table name (before any other subclause) and the options when LakeSoul reads include:"),(0,l.kt)("table",{parentName:"admonition"},(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,l.kt)("th",{parentName:"tr",align:null},"Explanation of meaning"),(0,l.kt)("th",{parentName:"tr",align:null},"Parameter filling format"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"readtype"),(0,l.kt)("td",{parentName:"tr",align:null},"read type, you can specify incremental read incremental, snapshot read snapshot, do not specify the default full read"),(0,l.kt)("td",{parentName:"tr",align:null},"'readtype'='incremental'")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"discoveryinterval"),(0,l.kt)("td",{parentName:"tr",align:null},"The time interval for discovering new data in streaming incremental read, in milliseconds, the default is 30000"),(0,l.kt)("td",{parentName:"tr",align:null},"'discoveryinterval'='10000'")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"readstarttime"),(0,l.kt)("td",{parentName:"tr",align:null},"Start read timestamp, if no start timestamp is specified, it will read from the start version number by default"),(0,l.kt)("td",{parentName:"tr",align:null},"'readstarttime'='2023-05-01 15:15:15'")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"readendtime"),(0,l.kt)("td",{parentName:"tr",align:null},"End read timestamp, if no end timestamp is specified, the current latest version number will be read by default"),(0,l.kt)("td",{parentName:"tr",align:null},"'readendtime'='2023-05-01 15:20:15'")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"timezone"),(0,l.kt)("td",{parentName:"tr",align:null},"The time zone information of the timestamp, if the time zone information of the timestamp is not specified, it will be processed according to the local time zone by default"),(0,l.kt)("td",{parentName:"tr",align:null},"'timezone'='Asia/Sahanghai'"))))))}k.isMDXComponent=!0}}]);