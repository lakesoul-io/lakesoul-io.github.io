"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[530],{3905:(e,a,t)=>{t.d(a,{Zo:()=>u,kt:()=>h});var n=t(7294);function o(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function l(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function r(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?l(Object(t),!0).forEach((function(a){o(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function s(e,a){if(null==e)return{};var t,n,o=function(e,a){if(null==e)return{};var t,n,o={},l=Object.keys(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||(o[t]=e[t]);return o}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var i=n.createContext({}),p=function(e){var a=n.useContext(i),t=a;return e&&(t="function"==typeof e?e(a):r(r({},a),e)),t},u=function(e){var a=p(e.components);return n.createElement(i.Provider,{value:a},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},d=n.forwardRef((function(e,a){var t=e.components,o=e.mdxType,l=e.originalType,i=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(t),d=o,h=c["".concat(i,".").concat(d)]||c[d]||m[d]||l;return t?n.createElement(h,r(r({ref:a},u),{},{components:t})):n.createElement(h,r({ref:a},u))}));function h(e,a){var t=arguments,o=a&&a.mdxType;if("string"==typeof e||o){var l=t.length,r=new Array(l);r[0]=d;var s={};for(var i in a)hasOwnProperty.call(a,i)&&(s[i]=a[i]);s.originalType=e,s[c]="string"==typeof e?e:o,r[1]=s;for(var p=2;p<l;p++)r[p]=t[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,t)}d.displayName="MDXCreateElement"},8134:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>i,contentTitle:()=>r,default:()=>m,frontMatter:()=>l,metadata:()=>s,toc:()=>p});var n=t(7462),o=(t(7294),t(3905));const l={},r="Snapshot Related API Usage Tutorial",s={unversionedId:"Tutorials/snapshot-manage",id:"Tutorials/snapshot-manage",title:"Snapshot Related API Usage Tutorial",description:"\x3c!--",source:"@site/docs/02-Tutorials/03-snapshot-manage.md",sourceDirName:"02-Tutorials",slug:"/Tutorials/snapshot-manage",permalink:"/docs/Tutorials/snapshot-manage",draft:!1,editUrl:"https://github.com/lakesoul-io/LakeSoul/tree/main/website/docs/02-Tutorials/03-snapshot-manage.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"LakeSoul Flink CDC Whole Database Synchronization Tutorial",permalink:"/docs/Tutorials/flink-cdc-sink/"},next:{title:"Mount LakeSoul Data to Hive Meta",permalink:"/docs/Tutorials/data-mount-to-hive"}},i={},p=[{value:"Snapshot Read",id:"snapshot-read",level:2},{value:"Snapshot Rollback",id:"snapshot-rollback",level:2},{value:"Snapshot Cleanup",id:"snapshot-cleanup",level:2}],u={toc:p},c="wrapper";function m(e){let{components:a,...t}=e;return(0,o.kt)(c,(0,n.Z)({},u,t,{components:a,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"snapshot-related-api-usage-tutorial"},"Snapshot Related API Usage Tutorial"),(0,o.kt)("p",null,"LakeSoul uses snapshots to record each updated file set and generate a new version number in the metadata. If the historical snapshot version has not been cleaned up, it can also be read, rolled back and cleaned up through the LakeSoul API. Since the snapshot version is an internal mechanism, LakeSoul provides a timestamp-based snapshot management API for convenience."),(0,o.kt)("p",null,"For snapshot read in Flink SQL, please refer to ",(0,o.kt)("a",{parentName:"p",href:"/docs/Usage%20Docs/flink-lakesoul-connector"},"Flink Connector"),"."),(0,o.kt)("h2",{id:"snapshot-read"},"Snapshot Read"),(0,o.kt)("p",null,"In some cases, it may be necessary to query the snapshot data of a partition of a table at a previous point in time, also known as Time Travel. The way LakeSoul performs reading a snapshot at a point in time:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'import com.dmetasoul.lakesoul.tables.LakeSoulTable\nimport org.apache.spark.sql._\nval spark = SparkSession. builder. master("local")\n  .config("spark.sql.extensions", "com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension")\n  .getOrCreate()\n\nval tablePath = "s3a://bucket-name/table/path/is/also/table/name"\n// Read the data of the \'date=2022-01-02\' partition when the timestamp is less than or equal to and closest to \'2022-01-01 15:15:15\'\nval lakeSoulTable = LakeSoulTable.forPathSnapshot(tablePath, "date=2022-01-02", "2022-01-01 15:15:15")\n')),(0,o.kt)("h2",{id:"snapshot-rollback"},"Snapshot Rollback"),(0,o.kt)("p",null,"Sometimes due to errors in newly written data, it is necessary to roll back to a certain historical snapshot version. How to perform a snapshot rollback to a point in time using LakeSoul:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"import com.dmetasoul.lakesoul.tables.LakeSoulTable\nimport org.apache.spark.sql._\nval spark = SparkSession. builder. master(\"local\")\n  .config(\"spark.sql.extensions\", \"com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nval lakeSoulTable = LakeSoulTable. forPath(tablePath)\n\n//Rollback metadata and storage data partitioned as '2021-01-02' when the timestamp is less than or equal to and the closest to '2022-01-01 15:15:15'\nlakeSoulTable.rollbackPartition(\"date='2022-01-02'\", \"2022-01-01 15:15:15\")\n//sql\nspark.sql(\"call LakeSoulTable.rollback(partitionvalue=>map('date','2022-01-02'),toTime=>'2022-01-01 15:15:15',tablePath=>'\" + tablePath + \"')\")\nspark.sql(\"call LakeSoulTable.rollback(partitionvalue=>map('date','2022-01-02'),toTime=>'2022-01-01 15:15:15',tzoneId=>'Asia/Shanghai',tableName=>'lakesoul')\")\n\n")),(0,o.kt)("p",null,"The rollback operation itself will create a new snapshot version, while other version snapshots and data will not be deleted."),(0,o.kt)("h2",{id:"snapshot-cleanup"},"Snapshot Cleanup"),(0,o.kt)("p",null,"If the historical snapshot is no longer needed, for example, Compaction has been executed, you can call the cleanup method to clean up the snapshot data before a certain point in time:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'import com.dmetasoul.lakesoul.tables.LakeSoulTable\nimport org.apache.spark.sql._\nval spark = SparkSession. builder. master("local")\n  .config("spark.sql.extensions", "com.dmetasoul.lakesoul.sql.LakeSoulSparkSessionExtension")\n  .getOrCreate()\n\nval tablePath = "s3a://bucket-name/table/path/is/also/table/name"\nval lakeSoulTable = LakeSoulTable. forPath(tablePath)\n\n//Clean up metadata and storage data partitioned as \'date=2022-01-02\' and earlier than "2022-01-01 15:15:15"\nlakeSoulTable.cleanupPartitionData("date=\'2022-01-02\'", "2022-01-01 15:15:15")\n')))}m.isMDXComponent=!0}}]);